# Autoencoder
This is the coursework produced for Neural Computing course at City, University of London. The work was produced in MATLAB with the help of my fellow classmate Federico Cardoni. We present a comparison of two neural networks applied to a digit recognition task on data from the widely-used MNIST dataset. We contrasted the Feedforward Multilayer Perceptron (MLP), a supervised learning algorithm, with a Stacked sparse Autoencoder (SAE), a deep network unsupervised one. Hyperparameters were varied in the training phase to achieve the best possible performance for each model, whose classification rate was compared on a separate test sample using Confusion Matrices. 
